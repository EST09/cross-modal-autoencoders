{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained model loaded from my_save_dir/models/701.pth\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "[-0.32383275  0.37668586  0.00569201 -2.838147   -0.88042605  0.9539123\n",
      "  0.01349318 -0.9595915   0.75821877  1.9814203   0.9068911   0.03429303\n",
      "  0.75307775 -1.143798    0.47421485 -1.399819    1.6820765  -0.80869997\n",
      " -1.3520637   0.6377118  -0.2971127  -0.75333136  0.75042224 -0.2760607\n",
      " -0.75222385 -0.38412046 -0.08199334  0.06715728 -1.511043   -0.59080094\n",
      "  0.7480022  -1.4513948  -2.0629723  -1.7580045   0.7013676  -1.1139015\n",
      " -0.1950953  -2.170839   -1.624953    0.81864536 -0.6336218   1.258681\n",
      " -0.05569905  0.0704729   1.2404164   0.38605106 -0.12464231 -3.1822426\n",
      "  0.96480316  1.955003    1.095408    1.5137548  -0.4481025  -0.30509484\n",
      "  0.96576124 -1.1446011  -1.4077638  -0.45957643  1.2354927   0.86194897\n",
      "  1.351218    0.6893929   0.03229361 -1.0858202  -0.00467342 -0.8790573\n",
      " -2.0847857   0.02711061 -0.7564238  -0.00336441 -0.5540901   1.4033707\n",
      "  2.7993875  -0.02461976  0.6197031   0.39659637  1.31428     1.6080894\n",
      "  0.55997527  0.52550834 -0.727518   -0.6374053   0.2519684   0.01837149\n",
      " -1.6008992  -0.54824513  0.89400464 -1.3127666  -0.208087    0.5891191\n",
      "  1.1301538  -2.9246905   1.7958704   0.67644006 -0.781364   -0.23807606\n",
      "  0.43722168 -0.10938203 -0.871614    0.9924638   0.05734551 -0.55999094\n",
      "  0.11565527 -0.06279796 -1.38838     1.2611156   0.48234773 -0.19794542\n",
      " -1.7593899   0.19830662  0.60706943 -0.02371839  0.5721908   0.68135405\n",
      " -0.6314291   0.03537399 -1.1542534  -1.4542413   0.32696947 -2.0378487\n",
      "  1.2978047  -0.12078834 -0.39209855 -0.44537762 -0.79223925  0.1686435\n",
      " -0.68928504 -1.3742701 ]\n",
      "[ 5.60548782e-01 -9.19136345e-01 -7.49488473e-01  1.18750370e+00\n",
      "  1.36773735e-02 -6.01688743e-01  3.89761925e-02  5.66366673e-01\n",
      "  9.79531765e-01 -5.81914902e-01 -4.69838083e-01  1.59797990e+00\n",
      "  1.17576575e+00  2.37297118e-01  5.98118454e-02  2.58463204e-01\n",
      "  4.30019826e-01 -4.96847272e-01  4.12154913e-01  2.20218390e-01\n",
      "  8.11448812e-01  1.46755517e-01 -1.54805851e+00  1.87423778e+00\n",
      "  4.67400789e-01  4.99950200e-01  8.25937331e-01  1.12970638e+00\n",
      "  1.64885187e+00 -4.41966981e-01 -1.97047782e+00  8.11760306e-01\n",
      " -6.82168841e-01 -1.02487123e+00  1.30500650e+00 -1.59702733e-01\n",
      "  8.38479996e-01 -1.43097413e+00 -9.80779231e-01 -2.22414708e+00\n",
      " -1.40914428e+00  3.37418377e-01  9.78624463e-01  8.88941586e-01\n",
      "  1.54505527e+00 -2.47070909e+00  4.65967238e-01 -4.67413604e-01\n",
      " -8.30061197e-01 -5.98075032e-01  3.31725985e-01 -6.03388190e-01\n",
      " -2.91400701e-01  2.17665076e-01 -5.70898712e-01 -3.14083517e-01\n",
      " -7.49970555e-01  1.75727570e+00 -2.65406775e+00  4.36975628e-01\n",
      "  1.40918458e+00 -7.68939078e-01 -3.22046697e-01  1.16879845e+00\n",
      "  2.16309214e+00 -5.18442929e-01 -1.00928903e+00 -2.42064357e+00\n",
      " -5.02031505e-01  1.14765212e-01  2.49013394e-01 -3.59262586e-01\n",
      "  8.77840221e-01  3.65856677e-01 -4.10875082e-01  2.22946912e-01\n",
      "  6.96056485e-01 -1.03254414e+00 -1.57117081e+00  2.79460847e-02\n",
      "  2.95079648e-02  3.04816818e+00 -4.93097395e-01 -1.26553679e+00\n",
      "  2.39032507e+00 -2.77680469e+00  1.24995148e+00  8.59698772e-01\n",
      " -6.01439178e-01 -1.15453649e+00  1.55104804e+00  4.15851593e-01\n",
      "  4.50441092e-02 -1.12473202e+00  5.23929000e-01  6.83035016e-01\n",
      " -1.88299567e-01 -9.14022505e-01  9.65415955e-01 -3.43562573e-01\n",
      "  1.41260028e-03 -1.93214250e+00 -1.79322517e+00  2.90418601e+00\n",
      "  1.68628299e+00 -2.37266034e-01 -1.06303960e-01  5.23695946e-01\n",
      " -2.06934437e-01  1.20094633e+00  4.62375432e-02  5.09308696e-01\n",
      " -1.08053017e+00 -6.00437403e-01  1.00711465e+00 -6.94246590e-01\n",
      " -3.84003103e-01 -1.17617404e+00  3.76980603e-01 -3.11288476e+00\n",
      " -1.70678556e-01 -1.28314590e+00 -2.18248153e+00  3.46307397e-01\n",
      " -1.43793356e+00 -2.26866066e-01  6.57972455e-01 -3.38893294e-01]\n",
      "[  0.10964406  -2.3635447    1.8589089   -3.3020942   -2.3623745\n",
      "   5.1067805    2.539155     1.7545639   -7.3851123   -5.4377465\n",
      "   1.1414697   -3.452598    -0.17875317   2.1836333    4.0471606\n",
      "   0.8443005   -2.1646876    0.15321958   2.7756977   -1.3161198\n",
      "  -3.2778769   -2.6350076   -0.53079927  -0.5269339    0.04886872\n",
      "  -1.5593148   -0.60097086   2.595784     2.0637379   -0.29597652\n",
      "   0.276945     1.5658957    4.951889    -5.293672    -1.8776423\n",
      "   0.04587007   2.3210042  -10.326023     3.6486545    3.3685765\n",
      "  -1.6586272    5.0669765   -1.1466119    0.3318866    4.205533\n",
      "   6.6488404   -6.7249155    2.8996608   -0.15360409  -0.514887\n",
      "  -0.5446328   -0.22953773   2.8652925   -2.8220592    1.4026332\n",
      "   2.1215148    0.35089946   1.3153522    1.8052765    0.23303545\n",
      "   2.7916934    4.2368402   -4.9890356   -0.5485252    2.2448115\n",
      "  -1.3398769    1.9187865    5.311732    -3.3579996    1.218024\n",
      "  -0.8700151    1.1916512   -2.2944703    0.26934308  -0.7347901\n",
      "  -1.6239543   -0.70271283  -0.72465944   4.3466287   -5.618683\n",
      "   0.70010793  -0.66908777   4.8193617    2.6565683   -1.7526877\n",
      "  -1.9159443    3.9896545   -0.6122152    3.6954167    3.972331\n",
      "  -0.6868331    2.2605083    4.9115615    2.6594825    1.6574687\n",
      "  -0.45045075  -1.6349137    0.61569804   5.894911    -2.317903\n",
      "   1.4696665    2.2137017    2.0285902   -1.3514438    1.867097\n",
      "   0.31082517   3.1594546   -3.0404212    1.3863258   -2.8373132\n",
      "  -0.41123578   1.9933652    1.7751243   -4.148534    -2.5596282\n",
      "   2.906181     3.105866     0.51169074   0.49236286   2.9844584\n",
      "  -2.3806598   -1.7306854   -3.192301     1.3935494    3.9271128\n",
      "  -1.9575481   -3.053746     5.6584034 ]\n",
      "[ 0.7530901   0.65131354  0.85246515 -0.129228   -0.9991914  -1.3892117\n",
      "  0.927282    0.8307488   0.04937521 -0.05449149  0.5223747   0.11060219\n",
      "  1.2745124  -1.3725789  -1.1940453  -0.16446611  2.1269517   1.3666258\n",
      " -1.479183   -0.6294793  -0.7299154  -0.20885727  0.15374601 -0.04523432\n",
      " -0.21542169 -1.732352    0.7668271   0.20911506 -0.9987151  -0.1387161\n",
      "  0.4833573  -0.10355157 -0.27203476  0.58364844 -1.6696874  -0.5234485\n",
      "  0.06800315 -1.3031282  -0.41309524  0.23962831  0.48907807 -0.53861064\n",
      "  1.0464637  -0.3248443   1.7408943  -0.03888854 -1.681744   -0.03586376\n",
      " -0.22654505 -0.38864163 -0.32589072  1.5091931  -0.7298725   1.0827008\n",
      " -0.05746708 -0.73962736  0.1217626   0.550439    0.33743426 -1.0445547\n",
      " -0.8554685  -0.8303171   2.693466   -0.6585992  -0.55439407 -1.9773848\n",
      "  1.4179966   1.7300949   0.6097418  -0.47433648  0.5045187  -1.1051753\n",
      "  1.2603606   0.9583149   0.12933126  1.047494   -1.0509582  -0.09082215\n",
      "  1.5175316  -0.8341402   0.02989057  0.5466194   0.5096807  -0.5997478\n",
      " -1.1695251   0.18137908  0.8129997   0.326459    0.34438968  0.1239996\n",
      "  0.09098926 -1.5955354  -0.46644926 -1.6942837  -0.17346323  0.28021514\n",
      "  1.1660144   1.1308236  -0.32417798 -0.1535252   1.0550842   0.41454428\n",
      "  1.0673829   1.285167   -0.65318936  0.88006103 -1.7846724   0.19549625\n",
      "  0.5841387   0.86608243  0.28816015  0.6843443  -1.1737251  -0.98594904\n",
      "  1.6380005  -0.389496   -0.7781973  -0.54459757  0.54079014 -2.435525\n",
      " -1.9493287   0.19324522  0.5455353  -1.0368617  -0.9299659   0.00523783\n",
      " -0.30700004  1.886712  ]\n",
      "[ 0.28508916  0.5083118  -1.2748823  -1.6637226   0.5589391  -1.1053375\n",
      "  0.22931713 -1.0954255  -0.19161817  0.37967673  1.7852921   1.6267021\n",
      " -0.5821008   0.39103165 -1.9002357  -0.2082412   0.7074934   2.7474544\n",
      " -0.15463811 -1.3859105   0.68642545 -0.1766437  -0.8148282   0.376278\n",
      " -0.10011095 -0.3594241   0.00316751 -0.6358807   1.1787148  -0.46664065\n",
      " -0.43081427  1.0479188   0.39986843  0.06792172  0.45183212  0.7244264\n",
      "  0.600768   -1.4376405   2.1813667  -1.0210292   0.14892748 -1.2769464\n",
      "  1.0218197  -0.24887398  0.5403845  -0.14496425 -2.0979297  -1.1103853\n",
      "  0.2886028   1.7544842  -0.6966901   0.48888272  0.13596416 -0.18452702\n",
      "  0.69051343  0.40217644 -0.57117987  0.44420677  1.7195857  -0.4028042\n",
      " -1.0868745  -1.3422098   0.18324615  1.3724033  -0.14697754 -1.1881876\n",
      "  0.07104263  0.8842343  -0.09990215 -0.4414469   1.7417786   0.9658693\n",
      "  0.4746795   1.4210961   0.991101   -0.89398277 -1.125264    1.0807678\n",
      " -0.54259956  1.9011326  -1.0359209  -0.1229682  -0.80175865  0.16350347\n",
      " -1.5556508   0.8670139  -0.26397127  0.68743527 -1.2531574   0.74345464\n",
      "  0.19678468  0.21892875 -0.24674332 -2.3919322  -0.3905967   0.8300524\n",
      " -0.14242528  2.8389175  -0.89183867 -0.83383846  1.0510687  -0.00838119\n",
      "  0.08267361 -0.17119631 -0.23927665  0.95878696 -0.28095797 -1.2420536\n",
      "  0.7600994   0.45477775  0.15758021  0.7903696  -0.8307389   2.0653446\n",
      " -0.2515925  -1.1748908  -0.08095437  0.55089486  0.38767314  0.71697026\n",
      "  0.1043416   1.1648023   0.66711783 -0.01410674 -0.14315867  1.0337452\n",
      " -0.6863785   0.9701315 ]\n",
      "[ 1.3152087e+00  7.9761100e-01 -1.2956318e+00 -6.6487700e-01\n",
      "  1.2713900e+00  2.0791501e-01  3.7939751e-01  1.7897987e-01\n",
      "  1.4366343e+00 -3.8886774e-01  8.2664287e-01 -4.3203852e-01\n",
      "  2.5410130e+00  3.9004251e-01 -3.4022480e-01 -6.5466094e-01\n",
      " -2.3161972e-01  3.6661422e-01  9.7268617e-01 -1.4134347e-01\n",
      " -3.3942717e-01 -3.7656364e-01 -4.3138194e-01  2.9138138e+00\n",
      "  1.3942361e+00 -1.8171540e+00  1.1811085e+00  4.0471697e-01\n",
      "  2.6199284e+00 -2.3845428e-01  7.0707059e-01 -1.5774488e+00\n",
      " -1.6593933e-04 -2.2377491e-01  1.6160835e+00 -2.5497630e-01\n",
      " -6.2215173e-01 -4.2384911e-01 -7.2774500e-01 -1.3542709e-01\n",
      "  1.7572846e+00 -6.7849910e-01  1.6797385e+00  3.1287128e-01\n",
      "  9.5007420e-01  1.0819757e+00 -1.4530239e-01 -2.6220292e-01\n",
      "  1.0343665e-01  3.3063457e+00  1.6275476e+00  2.2113302e+00\n",
      "  1.7043715e+00 -1.0670156e+00  9.3852341e-01 -1.0504987e+00\n",
      " -1.3597437e+00  6.2847471e-01  1.4278636e+00  9.3544567e-01\n",
      " -4.9938521e-01 -7.8542078e-01 -1.1846509e+00 -9.7787797e-02\n",
      " -2.1529894e+00  9.0506291e-01 -8.6658311e-01 -1.9151025e-02\n",
      " -2.8618088e+00  3.2721514e-01 -2.4719766e-01 -7.2312558e-01\n",
      "  7.3916483e-01  1.3028613e-01 -3.6913866e-01  4.2376846e-01\n",
      " -7.2378993e-01  1.5742149e+00  1.0878378e+00  6.4157832e-01\n",
      " -2.0009193e+00 -1.5316465e+00  8.3506513e-01 -6.1937165e-01\n",
      " -9.8632622e-01  1.2660075e+00  1.6395203e+00  6.4457059e-02\n",
      " -8.4134793e-01  1.7846504e-01  6.6187954e-01 -5.8709085e-01\n",
      "  2.4173675e+00 -1.0460290e+00  4.1068122e-01 -4.4875056e-01\n",
      " -4.3573657e-01 -9.7947121e-01 -5.9195721e-01 -9.5994025e-02\n",
      "  1.2041048e+00  9.0765917e-01 -9.0400797e-01  1.8117315e-01\n",
      " -3.8204831e-01  4.9002525e-01 -4.3220037e-01  1.4400120e+00\n",
      " -6.4793962e-01  1.4422860e+00  1.7693802e+00 -3.4527931e-01\n",
      " -1.8777716e-01  5.6052470e-01  6.7010045e-01 -2.2365183e-02\n",
      "  1.7698570e+00 -6.4515388e-01  1.0003890e+00  3.5371631e-01\n",
      " -5.5381685e-01  1.4047079e+00  3.9434892e-01 -1.8621423e+00\n",
      "  4.7714388e-01  1.2319317e+00 -3.5014659e-02  4.3891922e-02]\n",
      "[ 0.10966226 -1.0972166  -1.0607266   0.4631002  -0.7875592   1.5301317\n",
      " -0.45673186  0.22694725  0.8331734   0.37528437  0.11334139  0.40814775\n",
      "  1.93192    -1.197766    0.22217251 -0.73991495  1.3469201   1.6704336\n",
      " -1.80078     0.5158577   0.659961   -0.69686544 -0.9970102   2.8203306\n",
      "  0.33384725 -0.899078    0.81557    -1.2938907  -0.6447507   1.4073246\n",
      " -0.7356443   0.29119772  0.3031519  -1.0293758   0.270518   -0.25912523\n",
      "  0.27646255 -0.1576224   0.4754902   0.34250525  0.2969617  -0.44708714\n",
      "  0.8230541   0.20146352  1.4453688   1.3120012  -0.6231281   0.7591553\n",
      " -1.0017228   0.30026162 -0.1201908   0.75681454 -0.20826948  0.7222202\n",
      "  1.2519573   0.800306   -0.6841042   1.1184971  -0.71736944  2.2035172\n",
      "  0.02221316  0.4933737   1.8225766  -0.2397111   1.5391929   3.3202724\n",
      " -0.7426256   0.6210121   0.43699384 -1.4944483  -0.26573327  0.0149768\n",
      "  1.0406038   1.5737498   0.94923806 -2.4629936   0.28878617  0.44176292\n",
      "  0.7621346  -0.15370843 -0.66648185  1.0368675  -0.14047919 -0.4654835\n",
      " -1.4929891   0.75171137  0.36573893 -1.0418398  -1.1851399   1.1452078\n",
      "  0.23593993  0.6049473   0.8949994  -1.5426995  -2.5009508   0.41728556\n",
      "  0.5382605  -0.41650477  0.83136797 -0.7335909   1.0451627  -1.1786106\n",
      " -0.9547528   0.8160839   0.09138048  2.8720472   0.91981596 -0.9209372\n",
      " -1.9002113   0.6186835   0.5678682  -0.08664     0.57897794  0.05032954\n",
      " -1.1188695  -0.32725203  0.13528723 -1.7855788   1.0423176  -0.164215\n",
      " -0.00347974 -0.2503841   0.5730493  -0.15107283 -0.6423044   0.8063586\n",
      " -0.11207432  1.1732095 ]\n",
      "[ 0.18218698  0.31425017 -0.52243304 -1.6837296  -0.4362529  -1.6960049\n",
      "  0.6256882   0.869544    2.543703    1.7288753  -1.0028999   0.29906836\n",
      " -0.301072   -0.09239548 -1.6432247   1.445549   -0.5873477   2.060306\n",
      "  1.6554266   0.10224906 -0.32778904  0.5691296   0.2371167  -0.05881536\n",
      "  1.6075169   0.3187068   1.0789108   0.16690372 -0.25732952 -0.69640017\n",
      " -1.4567943  -0.61636364 -0.44639647 -0.65832794 -2.5378625  -1.6414192\n",
      "  0.74729174  1.2373868  -0.843484   -0.04575373 -0.8282861  -0.08206321\n",
      " -0.7607775   1.16403     1.5194596   0.06600386  1.5266134  -2.3895345\n",
      "  0.18331313  0.39684    -0.89385855 -0.45876533 -0.96758384  2.2883136\n",
      " -1.3135704   0.07722487  0.29922953  1.2906232  -1.4706111  -0.01042742\n",
      "  0.30551004 -1.3498051   1.7048786   1.5234218   1.3702768  -2.3064518\n",
      "  0.84895146 -2.2774587   1.624713    1.360186    2.221048    0.63910115\n",
      "  0.2645482  -0.7541868  -1.7980276   0.07056671 -2.380794   -1.0396354\n",
      "  0.98939306  1.4311235   0.45160946  0.277977   -0.32218933  0.22947694\n",
      "  0.90674984 -0.04176983  0.17095542  1.4975021  -0.09012325 -0.71603113\n",
      "  0.57177985 -0.54737854  1.3663588   0.00501046 -0.2696159  -0.5500909\n",
      " -0.46884602  0.5194832  -1.0162994   1.5210516  -1.2124478  -0.7242907\n",
      " -1.6241164  -1.3000003   1.0236084  -0.4066898  -1.9337304  -1.0887983\n",
      " -0.7999883  -0.22479033 -0.31086946  0.7685706  -0.4202511  -0.57261956\n",
      "  1.1961312  -0.12888812 -0.8276614   0.9278694   1.9034026  -1.4678776\n",
      " -1.0351201  -1.0463339  -1.4745585  -0.7388306  -1.3583097  -1.2312069\n",
      " -0.36995465 -2.5226011 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from final_dataloader import RNA_Dataset\n",
    "from final_dataloader import ImageDataset\n",
    "from model_from_master import FC_Autoencoder, FC_Classifier, VAE, FC_VAE, Simple_Classifier\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "#============ PARSE ARGUMENTS =============\n",
    "\n",
    "#parse arguments\n",
    "options = argparse.ArgumentParser()\n",
    "\n",
    "# save and directory options\n",
    "options.add_argument('-sd', '--save-dir', action=\"store\", dest=\"save_dir\", default=\"my_save_dir/rna\")\n",
    "options.add_argument('--save-freq', action=\"store\", dest=\"save_freq\", default=100, type=int)\n",
    "options.add_argument('--pretrained-file', action=\"store\", default=\"my_save_dir/models/701.pth\") #last epoch of train_ae.py\n",
    "\n",
    "# training parameters\n",
    "options.add_argument('-bs', '--batch-size', action=\"store\", dest=\"batch_size\", default=4, type=int) #32\n",
    "options.add_argument('-w', '--num-workers', action=\"store\", dest=\"num_workers\", default=10, type=int) \n",
    "options.add_argument('-lrAE', '--learning-rate-AE', action=\"store\", dest=\"learning_rate_AE\", default=1e-4, type=float)\n",
    "options.add_argument('-lrD', '--learning-rate-D', action=\"store\", dest=\"learning_rate_D\", default=1e-4, type=float)\n",
    "options.add_argument('-se', '--max-epochs', action=\"store\", dest=\"max_epochs\", default=10, type=int) # 800\n",
    "options.add_argument('-wd', '--weight-decay', action=\"store\", dest=\"weight_decay\", default=0, type=float)\n",
    "options.add_argument('--train-imagenet', action=\"store_true\")\n",
    "options.add_argument('--conditional', action=\"store_true\")\n",
    "options.add_argument('--conditional-adv', action=\"store_true\")\n",
    "\n",
    "# hyperparameters\n",
    "options.add_argument('--alpha', action=\"store\", default=0.1, type=float)\n",
    "options.add_argument('--beta', action=\"store\", default=1., type=float)\n",
    "options.add_argument('--lamb', action=\"store\", default=0.00000001, type=float)\n",
    "options.add_argument('--latent-dims', action=\"store\", default=128, type=int)\n",
    "\n",
    "# gpu options\n",
    "options.add_argument('-gpu', '--use-gpu', action=\"store_false\", dest=\"use_gpu\")\n",
    "\n",
    "args, unknown = options.parse_known_args()\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    args.use_gpu = False\n",
    "\n",
    "os.makedirs(args.save_dir, exist_ok=True)\n",
    "\n",
    "#============= TRAINING INITIALIZATION ==============\n",
    "\n",
    "# initialize autoencoder\n",
    "netRNA = FC_VAE(n_input=15814, nz=args.latent_dims)\n",
    "\n",
    "netImage = VAE(latent_variable_size=args.latent_dims, batchnorm=True)\n",
    "netImage.load_state_dict(torch.load(args.pretrained_file))\n",
    "print(\"Pre-trained model loaded from %s\" % args.pretrained_file)\n",
    "\n",
    "\n",
    "if args.use_gpu:\n",
    "    netRNA.cuda()\n",
    "    netImage.cuda()\n",
    "    \n",
    "\n",
    "# load data\n",
    "genomics_dataset = RNA_Dataset(datadir=\"data_folder/my_data/\")\n",
    "image_dataset = ImageDataset(datadir=\"data_folder/my_data//\", mode='test') #test\n",
    "\n",
    "image_loader = DataLoader(image_dataset, batch_size=args.batch_size, drop_last=True, shuffle=True)\n",
    "genomics_loader = DataLoader(genomics_dataset, batch_size=args.batch_size, drop_last=True, shuffle=True)\n",
    "\n",
    "# setup optimizer\n",
    "opt_netRNA = optim.Adam(list(netRNA.parameters()), lr=args.learning_rate_AE)\n",
    "opt_netImage = optim.Adam(list(netImage.parameters()), lr=args.learning_rate_AE)\n",
    "\n",
    "\n",
    "# loss criteria\n",
    "criterion_reconstruct = nn.MSELoss()\n",
    "criterion_classify = nn.CrossEntropyLoss()\n",
    "\n",
    "# setup logger\n",
    "with open(os.path.join(args.save_dir, 'log.txt'), 'w') as f:\n",
    "    print(args, file=f)\n",
    "    print(netRNA, file=f)\n",
    "    print(netImage, file=f)\n",
    "    \n",
    "\n",
    "# define helper train functions\n",
    "\n",
    "def compute_KL_loss(mu, logvar):\n",
    "    if args.lamb>0:\n",
    "        KLloss = -0.5*torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return args.lamb * KLloss\n",
    "    return 0\n",
    "\n",
    "def train_autoencoders(rna_inputs, image_inputs, rna_class_labels=None, image_class_labels=None):\n",
    "   \n",
    "    netRNA.train()\n",
    "    if args.train_imagenet:\n",
    "        netImage.train()\n",
    "    else:\n",
    "        netImage.eval()\n",
    "    \n",
    "    \n",
    "    # process input data\n",
    "    rna_inputs, image_inputs = Variable(rna_inputs), Variable(image_inputs)\n",
    "\n",
    "    if args.use_gpu:\n",
    "        rna_inputs, image_inputs = rna_inputs.cuda(), image_inputs.cuda()\n",
    "\n",
    "    # reset parameter gradients\n",
    "    netRNA.zero_grad()\n",
    "\n",
    "    # forward pass\n",
    "    rna_recon, rna_latents, rna_mu, rna_logvar = netRNA(rna_inputs)\n",
    "    image_recon, image_latents, image_mu, image_logvar = netImage(image_inputs)\n",
    "    \n",
    "    '''\n",
    "    if args.use_gpu:\n",
    "        rna_labels, image_labels = rna_labels.cuda(), image_labels.cuda()\n",
    "    '''    \n",
    "\n",
    "    # compute losses\n",
    "    rna_recon_loss = criterion_reconstruct(rna_inputs, rna_recon)\n",
    "    image_recon_loss = criterion_reconstruct(image_inputs, image_recon)\n",
    "    kl_loss = compute_KL_loss(rna_mu, rna_logvar) + compute_KL_loss(image_mu, image_logvar)\n",
    "    loss = args.alpha*(rna_recon_loss + image_recon_loss) + kl_loss\n",
    "\n",
    "    # backpropagate and update model\n",
    "    loss.backward()\n",
    "    opt_netRNA.step()\n",
    "    \n",
    "\n",
    "    if args.train_imagenet:\n",
    "        opt_netImage.step()\n",
    "\n",
    "    summary_stats = {'rna_recon_loss': rna_recon_loss.item(), 'image_recon_loss': image_recon_loss.item()}\n",
    "\n",
    "    return summary_stats\n",
    "\n",
    "\n",
    "def accuracy(output, target):\n",
    "    pred = output.argmax(dim=1).view(-1)\n",
    "    correct = pred.eq(target.view(-1)).float().sum().item()\n",
    "    return correct\n",
    "\n",
    "def generate_image(epoch):\n",
    "    img_dir = os.path.join(args.save_dir, \"images\")\n",
    "    os.makedirs(img_dir, exist_ok=True)\n",
    "    netRNA.eval()\n",
    "    netImage.eval()\n",
    "\n",
    "    for i in range(5):\n",
    "        samples = genomics_loader.dataset[np.random.randint(30)]\n",
    "        rna_inputs = samples['tensor']\n",
    "        rna_inputs = Variable(rna_inputs.unsqueeze(0))\n",
    "        samples = image_loader.dataset[np.random.randint(10)]\n",
    "        image_inputs = samples['image_tensor']\n",
    "        image_inputs = Variable(image_inputs.unsqueeze(0))\n",
    " \n",
    "        if torch.cuda.is_available():\n",
    "            rna_inputs = rna_inputs.cuda()\n",
    "            image_inputs = image_inputs.cuda()\n",
    " \n",
    "        _, rna_latents, _, _ = netRNA(rna_inputs)\n",
    "        recon_inputs = netImage.decode(rna_latents)\n",
    "        imageio.imwrite(os.path.join(img_dir, \"epoch_%s_trans_%s.jpg\" % (epoch, i)), np.uint8(recon_inputs.cpu().data.view(64,64).numpy()*255))\n",
    "        recon_images, _, _, _ = netImage(image_inputs)\n",
    "        imageio.imwrite(os.path.join(img_dir, \"epoch_%s_recon_%s.jpg\" % (epoch, i)), np.uint8(recon_images.cpu().data.view(64,64).numpy()*255))\n",
    " \n",
    "### main training loop\n",
    "for epoch in range(args.max_epochs):\n",
    "    print(epoch)\n",
    "\n",
    "    if epoch % args.save_freq == 0:\n",
    "        generate_image(epoch)\n",
    "\n",
    "    \n",
    "    recon_rna_loss = 0\n",
    "    recon_image_loss = 0\n",
    "\n",
    "    n_rna_correct = 0\n",
    "    n_rna_total = 0\n",
    "    \n",
    "    \n",
    "\n",
    "    for idx, (rna_samples, image_samples) in enumerate(zip(genomics_loader, image_loader)):\n",
    "        rna_inputs = rna_samples['tensor']\n",
    "        image_inputs = image_samples['image_tensor']\n",
    "\n",
    "        \n",
    "        out = train_autoencoders(rna_inputs, image_inputs)\n",
    "\n",
    "        recon_rna_loss += out['rna_recon_loss']\n",
    "        recon_image_loss += out['image_recon_loss']\n",
    "\n",
    "\n",
    "    with open(os.path.join(args.save_dir, 'log.txt'), 'a') as f:\n",
    "        print('Epoch: ', epoch, ', rna recon loss: %.8f' % float(recon_rna_loss), ', image recon loss: %.8f' % float(recon_image_loss), file=f)\n",
    "\n",
    "    # save model\n",
    "    if epoch % args.save_freq == 0:\n",
    "        torch.save(netRNA.cpu().state_dict(), os.path.join(args.save_dir,\"netRNA_%s.pth\" % epoch))\n",
    "        torch.save(netImage.cpu().state_dict(), os.path.join(args.save_dir,\"netImage_%s.pth\" % epoch))\n",
    "        \n",
    "\n",
    "    if args.use_gpu:\n",
    "        netRNA.cuda()\n",
    "        netImage.cuda()\n",
    "\n",
    "def plot_latent_space_with_labels(data_loader, model):\n",
    "    model = model.cuda()\n",
    "    '''\n",
    "    labels = []\n",
    "    for i, dict in enumerate(data_loader):\n",
    "        label = dict[\"label\"]\n",
    "        labels = labels + label\n",
    "    \n",
    "    d = {i:[] for i in labels}\n",
    "    '''\n",
    "    d = {}\n",
    "    with torch.no_grad():\n",
    "        for i, dict in enumerate(data_loader):\n",
    "            \n",
    "            images = dict[\"image_tensor\"]\n",
    "            labels1 = dict[\"label\"]\n",
    "            \n",
    "            embedding = model.get_latent_var(images.cuda())\n",
    "\n",
    "            for i, name in zip(range(len(labels1)), labels1):\n",
    "                    d[name] = embedding[i].to(\"cpu\").numpy()\n",
    "                \n",
    "    # print(d)\n",
    "    colors = list(mcolors.CSS4_COLORS.items())*10\n",
    "    for i,j in zip(list(d.keys()), range(len(list(d.keys())))):\n",
    "        print(d[i])\n",
    "        # d[i] = np.concatenate(d[i])\n",
    "        plt.scatter(\n",
    "            d[i][0], d[i][1],\n",
    "            color=colors[j][1],\n",
    "            label=f'{i}',\n",
    "            alpha=0.5)\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "plot_latent_space_with_labels(\n",
    "    data_loader=image_loader,\n",
    "    model=netImage.cuda())\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first create plot from image autoencoder\n",
    "\n",
    "# visualise latent space\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def plot_latent_space_with_labels(data_loader, model):\n",
    "    for i, dict in enumerate(data_loader):\n",
    "        print(dict)\n",
    "        labels = dict[\"label\"]\n",
    "    \n",
    "    d = {i:[] for i in labels}\n",
    "    print(d)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, dict in enumerate(data_loader):\n",
    "            \n",
    "            images = dict[\"image_tensor\"]\n",
    "            labels = dict[\"label\"]\n",
    "            \n",
    "            embedding = model.get_latent_var(images)\n",
    "            print(labels)\n",
    "            print(embedding)\n",
    "\n",
    "            for i, name in zip(range(len(labels)), labels):\n",
    "                \n",
    "                d[name].append(embedding[i].to('cpu').numpy())\n",
    "    \n",
    "    print(d)\n",
    "    colors = list(mcolors.CSS4_COLORS.items())*10\n",
    "    for i,j in zip(labels, range(len(labels))):\n",
    "        d[i] = np.concatenate(d[i])\n",
    "        plt.scatter(\n",
    "            d[i][0], d[i][1],\n",
    "            color=colors[j][1],\n",
    "            label=f'{i}',\n",
    "            alpha=0.5)\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplot_latent_space_with_labels(\\n    data_loader=image_loader,\\n    model=netImage)\\n\\nplt.legend()\\nplt.show()\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, dict in enumerate(image_loader):\n",
    "    print(i)\n",
    "\n",
    "'''\n",
    "plot_latent_space_with_labels(\n",
    "    data_loader=image_loader,\n",
    "    model=netImage)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "831cd48f08e2c97ff84c5d62c61bed6d148f2c8625d3fa4a1ddeb7d4ebc874c6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('auto_env_forge': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
