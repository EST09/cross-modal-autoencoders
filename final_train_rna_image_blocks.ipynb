{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7f9e6c29d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dependancies\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from final_parser import setup_args\n",
    "from final_dataloader import RNA_Dataset\n",
    "from final_dataloader import ImageDataset\n",
    "from final_model import FC_Autoencoder, FC_Classifier, VAE, FC_VAE, Simple_Classifier\n",
    "\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse arguments\n",
    "options = argparse.ArgumentParser()\n",
    "\n",
    "# save and directory options\n",
    "options.add_argument('-sd', '--save-dir', action=\"store\", dest=\"save_dir\", default=\"/Users/esthomas/Andor_Rotation/github_repo/cross-modal-autoencoders/my_save_dir\")\n",
    "options.add_argument('--save-freq', action=\"store\", dest=\"save_freq\", default=20, type=int)\n",
    "options.add_argument('--pretrained-file', action=\"store\", default=\"/Users/esthomas/Andor_Rotation/github_repo/cross-modal-autoencoders/my_save_dir/models/791.pth\") #last epoch of train_ae.py\n",
    "\n",
    "# training parameters\n",
    "options.add_argument('-bs', '--batch-size', action=\"store\", dest=\"batch_size\", default=4, type=int)\n",
    "options.add_argument('-w', '--num-workers', action=\"store\", dest=\"num_workers\", default=10, type=int)\n",
    "options.add_argument('-lrAE', '--learning-rate-AE', action=\"store\", dest=\"learning_rate_AE\", default=1e-4, type=float)\n",
    "options.add_argument('-lrD', '--learning-rate-D', action=\"store\", dest=\"learning_rate_D\", default=1e-4, type=float)\n",
    "options.add_argument('-e', '--max-epochs', action=\"store\", dest=\"max_epochs\", default=2, type=int)\n",
    "options.add_argument('-wd', '--weight-decay', action=\"store\", dest=\"weight_decay\", default=0, type=float)\n",
    "options.add_argument('--train-imagenet', action=\"store_true\")\n",
    "options.add_argument('--conditional', action=\"store_true\")\n",
    "options.add_argument('--conditional-adv', action=\"store_true\")\n",
    "\n",
    "# hyperparameters\n",
    "options.add_argument('--alpha', action=\"store\", default=0.1, type=float)\n",
    "options.add_argument('--beta', action=\"store\", default=1., type=float)\n",
    "options.add_argument('--lamb', action=\"store\", default=0.00000001, type=float)\n",
    "options.add_argument('--latent-dims', action=\"store\", default=128, type=int)\n",
    "\n",
    "# gpu options\n",
    "options.add_argument('-gpu', '--use-gpu', action=\"store_false\", dest=\"use_gpu\")\n",
    "\n",
    "args, unknown = options.parse_known_args()\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    args.use_gpu = False\n",
    "\n",
    "os.makedirs(args.save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained model loaded from /Users/esthomas/Andor_Rotation/github_repo/cross-modal-autoencoders/my_save_dir/models/791.pth\n"
     ]
    }
   ],
   "source": [
    "# training initialisation\n",
    "\n",
    "netRNA = FC_VAE(n_input=15814, nz=args.latent_dims) #used to be 7633\n",
    "netImage = VAE(latent_variable_size=args.latent_dims, batchnorm=True)\n",
    "netImage.load_state_dict(torch.load(args.pretrained_file))\n",
    "print(\"Pre-trained model loaded from %s\" % args.pretrained_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "netClf = FC_Classifier(nz=args.latent_dims) #latent space discriminator - model is using this one \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "genomics_dataset = RNA_Dataset(datadir=\"data_folder/my_data/\")\n",
    "image_dataset = ImageDataset(datadir=\"data_folder/my_data/\", mode='test')\n",
    "\n",
    "image_loader = torch.utils.data.DataLoader(image_dataset, batch_size=args.batch_size, drop_last=True, shuffle=True)\n",
    "genomics_loader = torch.utils.data.DataLoader(genomics_dataset, batch_size=args.batch_size, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup optimizer\n",
    "opt_netRNA = optim.Adam(list(netRNA.parameters()), lr=args.learning_rate_AE)\n",
    "opt_netClf = optim.Adam(list(netClf.parameters()), lr=args.learning_rate_D, weight_decay=args.weight_decay)\n",
    "opt_netImage = optim.Adam(list(netImage.parameters()), lr=args.learning_rate_AE)\n",
    "\n",
    "if args.conditional:\n",
    "    opt_netCondClf = optim.Adam(list(netCondClf.parameters()), lr=args.learning_rate_AE) #this does not run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss criteria\n",
    "criterion_reconstruct = nn.MSELoss()\n",
    "criterion_classify = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup logger\n",
    "with open(os.path.join(args.save_dir, 'log.txt'), 'w') as f:\n",
    "    print(args, file=f)\n",
    "    print(netRNA, file=f)\n",
    "    print(netImage, file=f)\n",
    "    print(netClf, file=f)\n",
    "    \n",
    "    if args.conditional:\n",
    "        print(netCondClf, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper train functions\n",
    "\n",
    "def compute_KL_loss(mu, logvar):\n",
    "    if args.lamb>0:\n",
    "        KLloss = -0.5*torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return args.lamb * KLloss\n",
    "    return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoders(rna_inputs, image_inputs, rna_class_labels=None, image_class_labels=None):\n",
    "   \n",
    "    netRNA.train() #FC_VAE\n",
    "    netImage.eval() #VAE\n",
    "    netClf.eval() #FC_Classifier\n",
    "    \n",
    "    # process input data\n",
    "    rna_inputs, image_inputs = Variable(rna_inputs), Variable(image_inputs)\n",
    "\n",
    "    # reset parameter gradients\n",
    "    netRNA.zero_grad()\n",
    "\n",
    "    # forward pass\n",
    "    rna_recon, rna_latents, rna_mu, rna_logvar = netRNA(rna_inputs)\n",
    "    image_recon, image_latents, image_mu, image_logvar = netImage(image_inputs)\n",
    "    \n",
    "    rna_scores = netClf(rna_latents)\n",
    "    image_scores = netClf(image_latents)\n",
    "\n",
    "    print(\"rna_scores\", rna_scores)\n",
    "    print(\"image_scores\", image_scores)\n",
    "\n",
    "    rna_labels = torch.zeros(rna_scores.size(0),).long()\n",
    "    image_labels = torch.ones(image_scores.size(0),).long()\n",
    "\n",
    "    print(\"rna_labels\", rna_labels)\n",
    "    print(\"image_labels\", image_labels)\n",
    "    \n",
    "    # compute losses\n",
    "    rna_recon_loss = criterion_reconstruct(rna_inputs, rna_recon) #nn.MSEloss\n",
    "    image_recon_loss = criterion_reconstruct(image_inputs, image_recon) #nn.MSEloss\n",
    "    kl_loss = compute_KL_loss(rna_mu, rna_logvar) + compute_KL_loss(image_mu, image_logvar)\n",
    "    clf_loss = 0.5*criterion_classify(rna_scores, image_labels) + 0.5*criterion_classify(image_scores, rna_labels)\n",
    "    loss = args.alpha*(rna_recon_loss + image_recon_loss) + clf_loss + kl_loss\n",
    "\n",
    "    # backpropagate and update model\n",
    "    loss.backward()\n",
    "    opt_netRNA.step()\n",
    "\n",
    "    summary_stats = {'rna_recon_loss': rna_recon_loss.item()*rna_scores.size(0), 'image_recon_loss': image_recon_loss.item()*image_scores.size(0), \n",
    "            'clf_loss': clf_loss.item()*(rna_scores.size(0)+image_scores.size(0))}\n",
    "    \n",
    "    return summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(rna_inputs, image_inputs, rna_class_labels=None, image_class_labels=None):\n",
    "    \n",
    "    netRNA.eval()\n",
    "    netImage.eval()\n",
    "    netClf.train()\n",
    "\n",
    "    # process input data\n",
    "    rna_inputs, image_inputs = Variable(rna_inputs), Variable(image_inputs)\n",
    "    \n",
    "    # reset parameter gradients\n",
    "    netClf.zero_grad()\n",
    "\n",
    "    # forward pass\n",
    "    _, rna_latents, _, _ = netRNA(rna_inputs)\n",
    "    _, image_latents, _, _ = netImage(image_inputs)\n",
    "\n",
    "    \n",
    "    rna_scores = netClf(rna_latents)\n",
    "    image_scores = netClf(image_latents)\n",
    "\n",
    "    rna_labels = torch.zeros(rna_scores.size(0),).long()\n",
    "    image_labels = torch.ones(image_scores.size(0),).long()\n",
    "\n",
    "    # compute losses\n",
    "    clf_loss = 0.5*criterion_classify(rna_scores, rna_labels) + 0.5*criterion_classify(image_scores, image_labels)\n",
    "\n",
    "    loss = clf_loss\n",
    "\n",
    "    # backpropagate and update model\n",
    "    loss.backward()\n",
    "    opt_netClf.step()\n",
    "\n",
    "    summary_stats = {'clf_loss': clf_loss*(rna_scores.size(0)+image_scores.size(0)), 'rna_accuracy': accuracy(rna_scores, rna_labels), 'rna_n_samples': rna_scores.size(0),\n",
    "            'image_accuracy': accuracy(image_scores, image_labels), 'image_n_samples': image_scores.size(0)}\n",
    "\n",
    "    return summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target):\n",
    "    pred = output.argmax(dim=1).view(-1)\n",
    "    correct = pred.eq(target.view(-1)).float().sum().item()\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(epoch):\n",
    "    img_dir = os.path.join(args.save_dir, \"images_recon\")\n",
    "    os.makedirs(img_dir, exist_ok=True)\n",
    "    netRNA.eval()\n",
    "    netImage.eval()\n",
    "\n",
    "    for i in range(5):\n",
    "        #This is no good? It's just a random selction? \n",
    "        #example: {'tensor': tensor([0., 1., 2.,  ..., 0., 0., 0.]), 'binary_label': '7_17_26'}\n",
    "        samples = genomics_loader.dataset[np.random.randint(30)]\n",
    "        rna_inputs = samples['tensor']\n",
    "        rna_inputs = Variable(rna_inputs.unsqueeze(0))\n",
    "        samples = image_loader.dataset[np.random.randint(10)]\n",
    "        image_inputs = samples['image_tensor']\n",
    "        image_inputs = Variable(image_inputs.unsqueeze(0))\n",
    " \n",
    "        _, rna_latents, _, _ = netRNA(rna_inputs)\n",
    "        recon_inputs = netImage.decode(rna_latents)\n",
    "        imageio.imwrite(os.path.join(img_dir, \"epoch_%s_trans_%s.jpg\" % (epoch, i)), np.uint8(recon_inputs.cpu().data.view(64,64).numpy()*255))\n",
    "        recon_images, _, _, _ = netImage(image_inputs)\n",
    "        imageio.imwrite(os.path.join(img_dir, \"epoch_%s_recon_%s.jpg\" % (epoch, i)), np.uint8(recon_images.cpu().data.view(64,64).numpy()*255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch\n",
      "torch.Size([1, 15814]) x\n",
      "torch.Size([1, 15814]) x\n",
      "torch.Size([1, 15814]) x\n",
      "torch.Size([1, 15814]) x\n",
      "torch.Size([1, 15814]) x\n",
      "torch.Size([4, 15814]) x\n",
      "rna_scores tensor([[ 0.0125,  0.0150],\n",
      "        [ 0.0048, -0.0120],\n",
      "        [ 0.0320,  0.0050],\n",
      "        [ 0.0209, -0.0574]], grad_fn=<AddmmBackward0>)\n",
      "image_scores tensor([[-0.0242, -0.0305],\n",
      "        [-3.2663,  0.5266],\n",
      "        [-0.0133,  0.0321],\n",
      "        [ 0.0690, -0.0113]], grad_fn=<AddmmBackward0>)\n",
      "rna_labels tensor([0, 0, 0, 0])\n",
      "image_labels tensor([1, 1, 1, 1])\n",
      "torch.Size([4, 15814]) x\n",
      "torch.Size([4, 15814]) x\n",
      "rna_scores tensor([[ 0.0466,  0.0078],\n",
      "        [ 0.0521, -0.0086],\n",
      "        [ 0.0272,  0.0018],\n",
      "        [ 0.0125, -0.0357]], grad_fn=<AddmmBackward0>)\n",
      "image_scores tensor([[ 0.0313, -0.0018],\n",
      "        [ 0.0345, -0.0498],\n",
      "        [-0.1073,  0.0259],\n",
      "        [-0.0144, -0.0225]], grad_fn=<AddmmBackward0>)\n",
      "rna_labels tensor([0, 0, 0, 0])\n",
      "image_labels tensor([1, 1, 1, 1])\n",
      "torch.Size([4, 15814]) x\n",
      "1 epoch\n",
      "torch.Size([4, 15814]) x\n",
      "rna_scores tensor([[ 0.0194, -0.0134],\n",
      "        [-0.0154, -0.0367],\n",
      "        [ 0.0215, -0.0335],\n",
      "        [ 0.0243, -0.0204]], grad_fn=<AddmmBackward0>)\n",
      "image_scores tensor([[ 0.0418, -0.0339],\n",
      "        [-0.0502, -0.0168],\n",
      "        [ 0.0231, -0.0862],\n",
      "        [-0.0065, -0.0786]], grad_fn=<AddmmBackward0>)\n",
      "rna_labels tensor([0, 0, 0, 0])\n",
      "image_labels tensor([1, 1, 1, 1])\n",
      "torch.Size([4, 15814]) x\n",
      "torch.Size([4, 15814]) x\n",
      "rna_scores tensor([[ 0.0552, -0.0015],\n",
      "        [ 0.0497,  0.0033],\n",
      "        [-0.0447, -0.0370],\n",
      "        [-0.0012, -0.0255]], grad_fn=<AddmmBackward0>)\n",
      "image_scores tensor([[-9.7588e-01, -1.1042e+01],\n",
      "        [ 6.7656e-04, -3.0161e-02],\n",
      "        [ 1.9795e-02, -6.8437e-02],\n",
      "        [-9.7558e-03,  6.7781e-03]], grad_fn=<AddmmBackward0>)\n",
      "rna_labels tensor([0, 0, 0, 0])\n",
      "image_labels tensor([1, 1, 1, 1])\n",
      "torch.Size([4, 15814]) x\n"
     ]
    }
   ],
   "source": [
    "### main training loop\n",
    "for epoch in range(args.max_epochs):\n",
    "    print(epoch, \"epoch\")\n",
    "    \n",
    "    if epoch % args.save_freq == 0:\n",
    "        generate_image(epoch)\n",
    "\n",
    "    recon_rna_loss = 0\n",
    "    recon_image_loss = 0\n",
    "    clf_loss = 0\n",
    "    clf_class_loss = 0\n",
    "    AE_clf_loss = 0\n",
    "\n",
    "    n_rna_correct = 0\n",
    "    n_rna_total = 0\n",
    "    n_atac_correct = 0\n",
    "    n_atac_total = 0\n",
    "    \n",
    "    for idx, (rna_samples, image_samples) in enumerate(zip(genomics_loader, image_loader)):\n",
    "        rna_inputs = rna_samples['tensor']\n",
    "        image_inputs = image_samples['image_tensor']\n",
    "\n",
    "        out = train_autoencoders(rna_inputs, image_inputs)\n",
    "\n",
    "        recon_rna_loss += out['rna_recon_loss']\n",
    "        recon_image_loss += out['image_recon_loss']\n",
    "        AE_clf_loss += out['clf_loss']\n",
    "\n",
    "        out = train_classifier(rna_inputs, image_inputs)\n",
    "\n",
    "        clf_loss += out['clf_loss']\n",
    "        n_rna_correct += out['rna_accuracy']\n",
    "        n_rna_total += out['rna_n_samples']\n",
    "        n_atac_correct += out['image_accuracy']\n",
    "        n_atac_total += out['image_n_samples']\n",
    "\n",
    "    \n",
    "    recon_rna_loss /= n_rna_total\n",
    "    clf_loss /= n_rna_total+n_atac_total\n",
    "    AE_clf_loss /= n_rna_total+n_atac_total\n",
    "\n",
    "    with open(os.path.join(args.save_dir, 'log.txt'), 'a') as f:\n",
    "        print('Epoch: ', epoch, ', rna recon loss: %.8f' % float(recon_rna_loss), ', image recon loss: %.8f' % float(recon_image_loss),\n",
    "                ', AE clf loss: %.8f' % float(AE_clf_loss), ', clf loss: %.8f' % float(clf_loss), ', clf class loss: %.8f' % float(clf_class_loss),\n",
    "                ', clf accuracy RNA: %.4f' % float(n_rna_correct / n_rna_total), ', clf accuracy ATAC: %.4f' % float(n_atac_correct / n_atac_total), file=f)\n",
    "\n",
    "    # save model\n",
    "    if epoch % args.save_freq == 0:\n",
    "        torch.save(netRNA.cpu().state_dict(), os.path.join(args.save_dir,\"netRNA_%s.pth\" % epoch))\n",
    "        torch.save(netImage.cpu().state_dict(), os.path.join(args.save_dir,\"netImage_%s.pth\" % epoch))\n",
    "        torch.save(netClf.cpu().state_dict(), os.path.join(args.save_dir,\"netClf_%s.pth\" % epoch))\n",
    "        if args.conditional:\n",
    "            torch.save(netCondClf.cpu().state_dict(), os.path.join(args.save_dir,\"netCondClf_%s.pth\" % epoch))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c3aa56e0440791a7df5a8adc369feb09c330a048a4485f923589840930ad4235"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('auto_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
