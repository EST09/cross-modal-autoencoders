{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from final_dataloader import ImageDataset\n",
    "import final_model as AENet\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = argparse.ArgumentParser()\n",
    "\n",
    "options.add_argument('--save-dir', action=\"store\", dest=\"save_dir\", default=\"my_save_dir\")\n",
    "options.add_argument('-pt', action=\"store\", dest=\"pretrained_file\", default=None)\n",
    "options.add_argument('-bs', action=\"store\", dest=\"batch_size\", default = 128, type = int) \n",
    "options.add_argument('-ds', action=\"store\", dest=\"datadir\", default = \"data_folder/my_data/\")\n",
    "\n",
    "options.add_argument('-iter', action=\"store\", dest=\"max_iter\", default = 800, type = int) #800\n",
    "options.add_argument('-lr', action=\"store\", dest=\"lr\", default=1e-3, type = float)\n",
    "options.add_argument('-nz', action=\"store\", dest=\"nz\", default=128, type = int)\n",
    "options.add_argument('-lamb', action=\"store\", dest=\"lamb\", default=0.0000001, type = float)\n",
    "options.add_argument('-lamb2', action=\"store\", dest=\"lamb2\", default=0.001, type = float)\n",
    "options.add_argument('--conditional', action=\"store_true\")\n",
    "\n",
    "args, unknown = options.parse_known_args()\n",
    "\n",
    "os.makedirs(args.save_dir, exist_ok=True)\n",
    "with open(os.path.join(args.save_dir, \"log.txt\"), 'w') as f:\n",
    "    print(args, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "# retrieve dataloader\n",
    "trainset = ImageDataset(datadir=args.datadir, mode='train')\n",
    "testset = ImageDataset(datadir=args.datadir, mode='test')\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=args.batch_size, drop_last=False, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=args.batch_size, drop_last=False, shuffle=False)\n",
    "\n",
    "print('Data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAE \n",
    "\n",
    "model = AENet.VAE(latent_variable_size=args.nz, batchnorm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_entropy\n",
    "CE_weights = torch.FloatTensor([4.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU model, ce\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU model, ce\")\n",
    "    model = model.to(device)\n",
    "    CE_weights = CE_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "CE = nn.CrossEntropyLoss(CE_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam([{'params': model.parameters()}], lr = args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar, latents):\n",
    "    MSE = nn.MSELoss()\n",
    "    lloss = MSE(recon_x,x)\n",
    "\n",
    "    if args.lamb>0:\n",
    "        KL_loss = -0.5*torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        lloss = lloss + args.lamb*KL_loss\n",
    "\n",
    "    return lloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    total_clf_loss = 0\n",
    "    \n",
    "    for batch_idx, samples in enumerate(train_loader):\n",
    " \n",
    "        inputs = Variable(samples['image_tensor'])\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            print(\"using_GPU\")\n",
    "            inputs=inputs.to(device)\n",
    "\n",
    "        \n",
    "        \n",
    " \n",
    "        optimizer.zero_grad()\n",
    "        recon_inputs, latents, mu, logvar = model(inputs)\n",
    "        loss = loss_function(recon_inputs, inputs, mu, logvar, latents)\n",
    "        train_loss += loss.data.item() * inputs.size(0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    with open(os.path.join(args.save_dir, \"log.txt\"), 'a') as f:\n",
    "        print('Epoch: {} Average loss: {:.15f} Clf loss: {:.15f} '.format(epoch, train_loss / len(train_loader.dataset), total_clf_loss / len(train_loader.dataset)), file=f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    \n",
    "\n",
    "    test_loss = 0\n",
    "    total_clf_loss = 0\n",
    "\n",
    "    for i, samples in enumerate(test_loader):\n",
    " \n",
    "        inputs = Variable(samples['image_tensor'])\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"using_GPU\")\n",
    "            inputs = inputs.to(device)\n",
    " \n",
    "        recon_inputs, latents, mu, logvar = model(inputs)\n",
    "        \n",
    "        loss = loss_function(recon_inputs, inputs, mu, logvar, latents)\n",
    "        test_loss += loss.data.item() * inputs.size(0)\n",
    "        \n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    total_clf_loss /= len(test_loader.dataset)\n",
    "\n",
    "    with open(os.path.join(args.save_dir, \"log.txt\"), 'a') as f:\n",
    "        print('Test set loss: {:.15f} Test clf loss: {:.15f}'.format(test_loss, total_clf_loss), file=f)\n",
    "    \n",
    "    return test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(epoch):\n",
    "    model_dir = os.path.join(args.save_dir, \"models\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    torch.save(model.cuda().state_dict(), os.path.join(model_dir, str(epoch)+\".pth\"))\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"model back to cuda\")\n",
    "        model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(epoch):\n",
    "    img_dir = os.path.join(args.save_dir, \"images\")\n",
    "    os.makedirs(img_dir, exist_ok=True)\n",
    "    model.eval()\n",
    "\n",
    "    for i in range(5):\n",
    "        samples = train_loader.dataset[np.random.randint(30)]\n",
    "        inputs = samples['image_tensor']\n",
    "        inputs = Variable(inputs.view(1,1,64,64))\n",
    " \n",
    "        if torch.cuda.is_available():\n",
    "            print(\"using_GPU inputs 1\")\n",
    "            inputs=inputs.cuda()\n",
    "            \n",
    "        print(next(model.parameters()).is_cuda) \n",
    "        print(inputs.is_cuda)    \n",
    "        recon_inputs, _, _, _ = model(inputs)\n",
    " \n",
    "        imageio.imwrite(os.path.join(img_dir, \"Train_epoch_%s_inputs_%s.jpg\" % (epoch, i)), np.uint8(inputs.cpu().data.view(64,64).numpy()*255))\n",
    "        imageio.imwrite(os.path.join(img_dir, \"Train_epoch_%s_recon_%s.jpg\" % (epoch, i)), np.uint8(recon_inputs.cpu().data.view(64,64).numpy()*255))\n",
    " \n",
    "        samples = test_loader.dataset[np.random.randint(5)]\n",
    "        inputs = samples['image_tensor']\n",
    "        inputs = Variable(inputs.view(1,1,64,64))\n",
    " \n",
    "        if torch.cuda.is_available():\n",
    "            print(\"using_GPU inputs\")\n",
    "            inputs=inputs.to(device)\n",
    " \n",
    "        recon_inputs, _, _, _ = model(inputs)\n",
    " \n",
    "        imageio.imwrite(os.path.join(img_dir, \"Test_epoch_%s_inputs_%s.jpg\" % (epoch, i)), np.uint8(inputs.cpu().data.view(64,64).numpy()*255))\n",
    "        imageio.imwrite(os.path.join(img_dir, \"Test_epoch_%s_recon_%s.jpg\" % (epoch, i)), np.uint8(recon_inputs.cpu().data.view(64,64).numpy()*255))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using_GPU inputs 1\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_557862/900655703.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# main training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerate_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_557862/3542360800.py\u001b[0m in \u001b[0;36mgenerate_image\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mrecon_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Train_epoch_%s_inputs_%s.jpg\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/auto_env_forge/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/cross-modal-autoencoders/final_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngf\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_latent_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x_lat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/cross-modal-autoencoders/final_model.py\u001b[0m in \u001b[0;36mreparametrize\u001b[0;34m(self, mu, logvar)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#encoded z_mean, z_log_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreparametrize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "# main training loop\n",
    "generate_image(0)\n",
    "save(0)\n",
    " \n",
    "_ = test(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42c560e8cb895bf07467abbf4ff855dbce625f075cb966bc1d52a3d7835416bb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('auto_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
